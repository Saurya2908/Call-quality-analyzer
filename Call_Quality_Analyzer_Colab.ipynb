{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0bd76ccf",
      "metadata": {
        "id": "0bd76ccf"
      },
      "source": [
        "# Call Quality Analyzer (Colab)\n",
        "Fast, lightweight pipeline that works on Colab Free and aims for <30s per call.\n",
        "\n",
        "**Test link**: https://www.youtube.com/watch?v=4ostqJD3Psc\n",
        "\n",
        "**What you get**\n",
        "1) Talk-time ratio per speaker  \n",
        "2) Number of questions asked  \n",
        "3) Longest monologue duration  \n",
        "4) Overall sentiment  \n",
        "5) One actionable insight  \n",
        "_Bonus_: heuristic label of Sales Rep vs Customer\n",
        "\n",
        "---\n",
        "### How it works (quick)\n",
        "- Download audio via `yt-dlp`, convert to 16 kHz mono.\n",
        "- Transcribe with **faster-whisper (tiny)** for speed + robustness.\n",
        "- **Lightweight diarization**: extract MFCC embeddings in short windows and **KMeans (k=2)** to separate speakers; merge contiguous segments.\n",
        "- Compute metrics from aligned words+segments.\n",
        "- Sentiment via **NLTK VADER** (fast, no GPU).\n",
        "- Actionable insight is generated from ratios, question counts, and sentiment.\n",
        "\n",
        "Run cells top-to-bottom. Comments explain each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3e25b116",
      "metadata": {
        "id": "3e25b116"
      },
      "outputs": [],
      "source": [
        "#@title 1) Setup (installs) â€” ~10-20s\n",
        "!pip install -q yt-dlp faster-whisper==1.0.3 librosa==0.10.2.post1 pydub==0.25.1 numpy==1.26.4 scipy==1.13.1 scikit-learn==1.3.2 nltk==3.9.1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6a8c406d",
      "metadata": {
        "id": "6a8c406d"
      },
      "outputs": [],
      "source": [
        "#@title 2) Imports & small utils\n",
        "import os, re, math, json, tempfile, subprocess, sys\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "from sklearn.cluster import KMeans\n",
        "from faster_whisper import WhisperModel\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def hhmmss(seconds: float) -> str:\n",
        "    seconds = max(0, float(seconds))\n",
        "    h = int(seconds // 3600); seconds -= h*3600\n",
        "    m = int(seconds // 60); s = seconds - m*60\n",
        "    if h: return f\"{h:d}:{m:02d}:{s:04.1f}\"\n",
        "    return f\"{m:d}:{s:04.1f}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7f324d81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f324d81",
        "outputId": "024effbb-f33c-47cd-9d19-92546e620cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: call_16k_mono.wav Size: 3834 KB\n"
          ]
        }
      ],
      "source": [
        "#@title 3) Download audio from YouTube (or provide your own file path)\n",
        "YT_URL = \"https://www.youtube.com/watch?v=4ostqJD3Psc\"  #@param {type:\"string\"}\n",
        "OUTPUT_WAV = \"call_16k_mono.wav\"\n",
        "\n",
        "# Use yt-dlp to pull audio best quality, then convert to 16k mono wav via ffmpeg\n",
        "# This remains fast on Colab Free.\n",
        "tmp_m4a = \"tmp_audio.m4a\"\n",
        "!yt-dlp -f bestaudio -x --audio-format m4a -o \"{tmp_m4a}\" \"{YT_URL}\" -q\n",
        "\n",
        "# Convert to 16k mono wav for consistent processing\n",
        "!ffmpeg -y -i \"{tmp_m4a}\" -ac 1 -ar 16000 \"{OUTPUT_WAV}\" -loglevel error\n",
        "\n",
        "print(\"Saved:\", OUTPUT_WAV, \"Size:\", os.path.getsize(OUTPUT_WAV)//1024, \"KB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b2a18536",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2a18536",
        "outputId": "18a7646a-d009-46d3-ad42-475556e4467a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription done. Duration (s): 122.72\n",
            "Approx. words: 327\n"
          ]
        }
      ],
      "source": [
        "#@title 4) Transcribe quickly with faster-whisper (tiny)\n",
        "AUDIO_PATH = OUTPUT_WAV\n",
        "\n",
        "# tiny is fast; beam_size=1 and vad_filter improves speed/robustness on noisy audio.\n",
        "model = WhisperModel(\"tiny\", device=\"cpu\", compute_type=\"int8\")\n",
        "segments, info = model.transcribe(AUDIO_PATH, beam_size=1, vad_filter=True, word_timestamps=True)\n",
        "\n",
        "words = []  # flatten word-level timings\n",
        "transcript_text = []\n",
        "for seg in segments:\n",
        "    if seg.words:\n",
        "        for w in seg.words:\n",
        "            words.append({\"start\": w.start, \"end\": w.end, \"text\": w.word})\n",
        "            transcript_text.append(w.word)\n",
        "    else:\n",
        "        # fallback if words missing\n",
        "        words.append({\"start\": seg.start, \"end\": seg.end, \"text\": seg.text})\n",
        "        transcript_text.append(seg.text)\n",
        "\n",
        "full_text = \" \".join(t[\"text\"] for t in words).strip()\n",
        "print(\"Transcription done. Duration (s):\", round(info.duration, 2))\n",
        "print(\"Approx. words:\", len(words))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ab97f73e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab97f73e",
        "outputId": "e338ff9f-8522-4975-dfad-d8897e1734c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speaker segments: 5\n",
            "Total duration: 2:02.7\n"
          ]
        }
      ],
      "source": [
        "#@title 5) Lightweight 2-speaker diarization (fast KMeans on MFCC windows)\n",
        "# Window the audio, compute MFCC mean+var features per window, then KMeans(k=2).\n",
        "# Map windows back to time to get speaker turns and merge contiguous segments.\n",
        "\n",
        "y, sr = librosa.load(AUDIO_PATH, sr=16000, mono=True)\n",
        "win_sec = 1.5\n",
        "hop_sec = 0.5\n",
        "win = int(win_sec*sr)\n",
        "hop = int(hop_sec*sr)\n",
        "\n",
        "features = []\n",
        "times = []\n",
        "for start in range(0, len(y)-win, hop):\n",
        "    yw = y[start:start+win]\n",
        "    mfcc = librosa.feature.mfcc(y=yw, sr=sr, n_mfcc=13)\n",
        "    feat = np.concatenate([mfcc.mean(axis=1), mfcc.var(axis=1)])\n",
        "    features.append(feat)\n",
        "    times.append((start/sr, (start+win)/sr))\n",
        "\n",
        "features = np.array(features)\n",
        "kmeans = KMeans(n_clusters=2, n_init=10, random_state=42)\n",
        "labels = kmeans.fit_predict(features)\n",
        "\n",
        "# Build merged segments per speaker label\n",
        "merged = []\n",
        "for (t0,t1), lab in zip(times, labels):\n",
        "    if not merged:\n",
        "        merged.append([t0,t1,lab])\n",
        "    else:\n",
        "        if lab == merged[-1][2] and t0 <= merged[-1][1] + 0.05:\n",
        "            merged[-1][1] = t1  # extend\n",
        "        else:\n",
        "            merged.append([t0,t1,lab])\n",
        "\n",
        "# Clip within audio duration\n",
        "duration = len(y)/sr\n",
        "for seg in merged:\n",
        "    seg[0] = max(0.0, seg[0]); seg[1] = min(duration, seg[1])\n",
        "\n",
        "# Prepare speaker map (S0, S1)\n",
        "speaker_map = {0: \"S0\", 1: \"S1\"}  # temporary; we'll relabel with bonus heuristic later\n",
        "speaker_segments = [{\"start\": s, \"end\": e, \"label\": speaker_map[l]} for s,e,l in merged if e > s]\n",
        "\n",
        "print(\"Speaker segments:\", len(speaker_segments))\n",
        "print(\"Total duration:\", hhmmss(duration))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e1fd2342",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1fd2342",
        "outputId": "8c80e4af-6376-4983-877a-006e8e212f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assigned words with speakers: 327\n"
          ]
        }
      ],
      "source": [
        "#@title 6) Align words to speakers\n",
        "# For each word, find the segment that overlaps its midpoint and assign that speaker.\n",
        "def assign_speaker(words, segments):\n",
        "    seg_idx = 0\n",
        "    assigned = []\n",
        "    for w in words:\n",
        "        mid = 0.5*(w[\"start\"] + w[\"end\"])\n",
        "        # advance seg_idx until segment covers mid\n",
        "        while seg_idx < len(segments) and segments[seg_idx][\"end\"] < mid:\n",
        "            seg_idx += 1\n",
        "        spk = None\n",
        "        if seg_idx < len(segments) and segments[seg_idx][\"start\"] <= mid <= segments[seg_idx][\"end\"]:\n",
        "            spk = segments[seg_idx][\"label\"]\n",
        "        assigned.append({**w, \"speaker\": spk or \"UNK\"})\n",
        "    return assigned\n",
        "\n",
        "words_spk = assign_speaker(words, speaker_segments)\n",
        "print(\"Assigned words with speakers:\", len(words_spk))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3713f152",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3713f152",
        "outputId": "1aa1534f-8ca2-4e0e-a135-e577993d8b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Talk-time ratio: {'S0': 96.4, 'S1': 3.6}\n",
            "Questions by speaker: {'S0': 8}  Total: 8\n",
            "Longest monologue: 111.5 s by S0 (0:07.0â€“1:58.5)\n",
            "Overall sentiment: positive {'neg': 0.008, 'neu': 0.794, 'pos': 0.198, 'compound': 0.9927}\n"
          ]
        }
      ],
      "source": [
        "#@title 7) Metrics: talk-time, question count, longest monologue, sentiment\n",
        "from collections import defaultdict\n",
        "\n",
        "# Talk-time per speaker\n",
        "dur_per_spk = defaultdict(float)\n",
        "for seg in speaker_segments:\n",
        "    dur_per_spk[seg[\"label\"]] += (seg[\"end\"] - seg[\"start\"])\n",
        "\n",
        "total_talk = sum(dur_per_spk.values()) or 1e-6\n",
        "talk_ratio = {spk: round(100.0*dur/total_talk, 1) for spk, dur in dur_per_spk.items()}\n",
        "\n",
        "# Questions: simple heuristic â€” sentences ending with '?' OR starting with WH- words\n",
        "text_by_spk = defaultdict(list)\n",
        "for w in words_spk:\n",
        "    text_by_spk[w[\"speaker\"]].append(w[\"text\"])\n",
        "joined_by_spk = {spk: \" \".join(toks) for spk, toks in text_by_spk.items()}\n",
        "\n",
        "def count_questions(text):\n",
        "    # count '?' and wh-question patterns\n",
        "    q_mark = text.count(\"?\")\n",
        "    sents = re.split(r\"(?<=[\\.!?])\\s+\", text)\n",
        "    wh = sum(1 for s in sents if re.match(r\"\\s*(who|what|when|where|why|how|which|can|could|would|should|do|does|did)\\b\", s.strip(), re.IGNORECASE))\n",
        "    return max(q_mark, wh)\n",
        "\n",
        "questions_total = 0\n",
        "questions_per_spk = {}\n",
        "for spk, tx in joined_by_spk.items():\n",
        "    qc = count_questions(tx)\n",
        "    questions_per_spk[spk] = qc\n",
        "    questions_total += qc\n",
        "\n",
        "# Longest monologue (max contiguous segment)\n",
        "longest = 0.0; longest_spk = None; longest_span = (0,0)\n",
        "for seg in speaker_segments:\n",
        "    d = seg[\"end\"] - seg[\"start\"]\n",
        "    if d > longest:\n",
        "        longest = d; longest_spk = seg[\"label\"]; longest_span = (seg[\"start\"], seg[\"end\"])\n",
        "\n",
        "# Sentiment via VADER on full transcript\n",
        "sent_scores = sia.polarity_scores(\" \".join(tok for tok in full_text.split()))\n",
        "sentiment = max(sent_scores, key=sent_scores.get)  # 'pos','neu','neg','compound'; compound usually max magnitude\n",
        "overall_sent = \"positive\" if sent_scores[\"compound\"] >= 0.25 else (\"negative\" if sent_scores[\"compound\"] <= -0.25 else \"neutral\")\n",
        "\n",
        "print(\"Talk-time ratio:\", talk_ratio)\n",
        "print(\"Questions by speaker:\", questions_per_spk, \" Total:\", questions_total)\n",
        "print(\"Longest monologue:\", round(longest,1), \"s by\", longest_spk, f\"({hhmmss(longest_span[0])}â€“{hhmmss(longest_span[1])})\")\n",
        "print(\"Overall sentiment:\", overall_sent, sent_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b1f0163e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1f0163e",
        "outputId": "07ba372d-905a-405d-a7b4-ea40dfc226c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Role scores: {'S0': 28.28}\n",
            "Heuristic roles: {'S0': 'Sales Rep', 'S1': 'Customer'}\n"
          ]
        }
      ],
      "source": [
        "#@title 8) Bonus heuristic: label Sales Rep vs Customer\n",
        "# Heuristics (cheap, fast):\n",
        "# - Sales rep tends to ask more questions, uses sales keywords, and may speak more.\n",
        "sales_keywords = set(\"\"\"price pricing demo discount trial contract plan subscription quote upgrade onboarding features roadmap integration api support invoice budget stakeholder proposal pilot deployment competitor timeline requirement next steps follow-up\"\"\".split())\n",
        "\n",
        "def score_sales_like(text):\n",
        "    toks = re.findall(r\"[a-z']+\", text.lower())\n",
        "    return sum(1 for t in toks if t in sales_keywords)\n",
        "\n",
        "spk_scores = {}\n",
        "for spk, tx in joined_by_spk.items():\n",
        "    spk_scores[spk] = 1.0*questions_per_spk.get(spk,0) + 0.5*score_sales_like(tx) + 0.2*talk_ratio.get(spk,0)\n",
        "\n",
        "# Higher score => more likely the Sales Rep\n",
        "if len(spk_scores) >= 2:\n",
        "    sales_spk = max(spk_scores, key=spk_scores.get)\n",
        "    customer_spk = [s for s in spk_scores.keys() if s != sales_spk][0]\n",
        "else:\n",
        "    sales_spk, customer_spk = \"S0\", \"S1\"\n",
        "\n",
        "role_map = {sales_spk: \"Sales Rep\", customer_spk: \"Customer\"}\n",
        "print(\"Role scores:\", spk_scores)\n",
        "print(\"Heuristic roles:\", role_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5e6c699f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e6c699f",
        "outputId": "f32266f3-2ca8-4f31-b97e-e922c17b0dbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actionable insight: Sales Rep dominated the call. Aim for a more balanced split.\n"
          ]
        }
      ],
      "source": [
        "#@title 9) Actionable insight (simple rule-based)\n",
        "insights = []\n",
        "\n",
        "# Balance suggestion\n",
        "diff = abs(talk_ratio.get(\"S0\",0) - talk_ratio.get(\"S1\",0))\n",
        "if diff > 20:\n",
        "    dominant = max(talk_ratio, key=talk_ratio.get)\n",
        "    insights.append(f\"{role_map.get(dominant, dominant)} dominated the call. Aim for a more balanced split.\")\n",
        "\n",
        "# Question suggestion\n",
        "asker = max(questions_per_spk, key=questions_per_spk.get) if questions_per_spk else None\n",
        "if asker:\n",
        "    other = [s for s in talk_ratio if s != asker]\n",
        "    if other:\n",
        "        other = other[0]\n",
        "        if questions_per_spk[asker] < 5:\n",
        "            insights.append(f\"Ask more open-ended questions to uncover needs (only {questions_per_spk[asker]} questions asked).\")\n",
        "\n",
        "# Sentiment suggestion\n",
        "if overall_sent == \"negative\":\n",
        "    t0, t1 = longest_span\n",
        "    insights.append(\"Address objections early; sentiment skewed negative.\")\n",
        "elif overall_sent == \"neutral\":\n",
        "    insights.append(\"Try adding a clear value statement and next steps to lift sentiment.\")\n",
        "\n",
        "actionable = insights[0] if insights else \"Summarize needs, confirm next steps, and schedule follow-up.\"\n",
        "\n",
        "print(\"Actionable insight:\", actionable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "16f1d729",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16f1d729",
        "outputId": "3f7be5af-cc02-4134-f03d-818d3f4c1a25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"talk_time_ratio_percent\": {\n",
            "    \"S0\": 96.4,\n",
            "    \"S1\": 3.6\n",
            "  },\n",
            "  \"questions_per_speaker\": {\n",
            "    \"S0\": 8\n",
            "  },\n",
            "  \"questions_total\": 8,\n",
            "  \"longest_monologue_seconds\": 111.5,\n",
            "  \"longest_monologue_speaker\": \"S0\",\n",
            "  \"longest_monologue_span\": {\n",
            "    \"start_sec\": 7.0,\n",
            "    \"end_sec\": 118.5\n",
            "  },\n",
            "  \"overall_sentiment\": \"positive\",\n",
            "  \"roles\": {\n",
            "    \"S0\": \"Sales Rep\",\n",
            "    \"S1\": \"Customer\"\n",
            "  },\n",
            "  \"actionable_insight\": \"Sales Rep dominated the call. Aim for a more balanced split.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#@title 10) Final report\n",
        "report = {\n",
        "    \"talk_time_ratio_percent\": talk_ratio,\n",
        "    \"questions_per_speaker\": questions_per_spk,\n",
        "    \"questions_total\": int(sum(questions_per_spk.values())),\n",
        "    \"longest_monologue_seconds\": round(float(max((seg[\"end\"]-seg[\"start\"]) for seg in speaker_segments)),1) if speaker_segments else 0.0,\n",
        "    \"longest_monologue_speaker\": longest_spk,\n",
        "    \"longest_monologue_span\": {\"start_sec\": round(longest_span[0],1), \"end_sec\": round(longest_span[1],1)},\n",
        "    \"overall_sentiment\": overall_sent,\n",
        "    \"roles\": role_map,\n",
        "    \"actionable_insight\": actionable,\n",
        "}\n",
        "\n",
        "print(json.dumps(report, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1f44e8e",
      "metadata": {
        "id": "b1f44e8e"
      },
      "source": [
        "---\n",
        "## Notes\n",
        "- This notebook avoids heavy diarization models for speed; the KMeans MFCC approach is robust enough for 2-speaker sales calls.\n",
        "- For longer calls, consider switching `WhisperModel('base')` (still fast) or enabling GPU in Colab if available.\n",
        "- Metrics are deterministic and explained in comments for review.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}